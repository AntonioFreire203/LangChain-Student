{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PromptTemplate — Criação de Prompts com Variáveis Dinâmicas\n",
    "Objeto:\n",
    "\n",
    "PromptTemplate é um modelo reutilizável de texto com espaços reservados (placeholders) para valores dinâmicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "Você é um assistente que traduz do {input_language} para o {output_language}.\n",
    "\"\"\"\n",
    "\n",
    "# Criando o prompt\n",
    "prompt_template = PromptTemplate(template=TEMPLATE, input_variables=[\"input_language\", \"output_language\"])\n",
    "\n",
    "# Formatando com valores reais\n",
    "prompt_template.format(input_language=\"inglês\", output_language=\"alemão\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-Shot Prompting — Exemplos dentro do Prompt\n",
    " Objeto:\n",
    "\n",
    "PromptTemplate com exemplos embutidos no texto. Útil para mostrar ao modelo como você quer que ele pense ou responda\n",
    "\n",
    "Vantagens:\n",
    "\n",
    "    Melhora a qualidade e consistência da resposta\n",
    "\n",
    "    Mostra ao modelo o formato esperado\n",
    "\n",
    "    Muito usado em NLP tradicional + LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Interprete o texto e classifique:\n",
    "- sentimento (positivo, neutro, negativo)\n",
    "- assunto (uma palavra)\n",
    "\n",
    "Formato JSON:\n",
    "sentiment\n",
    "subject\n",
    "\n",
    "Texto: {input}\n",
    "\n",
    "Exemplos:\n",
    "Texto: A loja esportiva Centauro oferece uma experiência maravilhosa na compra de material esportivo em geral\n",
    "sentiment: positivo\n",
    "subject: Centauro\n",
    "\n",
    "Texto: Centauro tive um atendimento mediano. Os produtos são ok...\n",
    "sentiment: neutro\n",
    "subject: Centauro\n",
    "\n",
    "Texto: Centauro tem um produto horrivel. E o atendimento de saq foi horrivel...\n",
    "sentiment: negativo\n",
    "subject: Centauro\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=TEMPLATE, input_variables=[\"input\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. **FewShotPromptTemplate** — Modularização de Exemplos\n",
    " Objeto:\n",
    "\n",
    "**FewShotPromptTemplate** permite criar prompts com exemplos estruturados, separados por **chave** e **valor**.\n",
    "\n",
    "Vantagens:\n",
    "\n",
    "    Separação clara entre exemplos e estrutura\n",
    "\n",
    "    Mais flexível e escalável\n",
    "\n",
    "    Facilita adicionar/remover exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"text\": \"O atendimento foi ótimo!\", \"response\": \"sentiment: positivo\\nsubject: atendimento\"},\n",
    "    {\"text\": \"O produto estava danificado.\", \"response\": \"sentiment: negativo\\nsubject: loja\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"response\"],\n",
    "    template=\"Texto: {text}\\n{response}\"\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Texto: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"O camisa que comprei veio com defeito na manga da camisa.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Chain-of-Thought Prompting** — Explicações no Prompt\n",
    " Objeto:\n",
    " Ainda é um PromptTemplate, mas agora com explicações passo a passo, mostrando como o modelo deve pensar antes de responder.\n",
    "\n",
    " Vantagens:\n",
    "\n",
    "    Leva o modelo a \"raciocinar\"\n",
    "\n",
    "    Aumenta precisão em tarefas complexas\n",
    "\n",
    "    Reduz erros por falta de contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Texto: {input}\n",
    "\n",
    "Vamos pensar juntos:\n",
    "\"O produto estava danificado, e o atendimento foi ruim.\" O que isso nos diz?\n",
    "É uma crítica negativa.\n",
    "\n",
    "Resposta em JSON:\n",
    "{ \"sentiment\": \"negativo\", \"subject\": \"loja\" }\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PipelinePromptTemplate** — Composição de Prompts\n",
    " Objeto:\n",
    "\n",
    "**PipelinePromptTemplate** permite juntar vários templates pequenos para montar um prompt maior, organizado por seções (ex: introdução, exemplo, execução).\n",
    "\n",
    "**Vantagens**:\n",
    "\n",
    "    Permite reutilizar blocos de texto\n",
    "\n",
    "    Ideal para projetos mais complexos e dinâmicos\n",
    "\n",
    "    Deixa o código modular e limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "# Define partes do prompt\n",
    "introduction = PromptTemplate.from_template(\"Você vai analisar sentimentos em textos.\")\n",
    "example = PromptTemplate.from_template(\"Texto: {example_text}\\nResposta: {example_response}\")\n",
    "execution = PromptTemplate.from_template(\"Agora analise o seguinte: {input}\")\n",
    "\n",
    "full_template = \"{introduction}\\n\\n{example}\\n\\n{execution}\"\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=PromptTemplate.from_template(full_template),\n",
    "    pipeline_prompts=[\n",
    "        (\"introduction\", introduction),\n",
    "        (\"example\", example),\n",
    "        (\"execution\", execution)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(pipeline_prompt.format(\n",
    "    example_text=\"O restaurante estava excelente!\",\n",
    "    example_response='{ \"sentiment\": \"positivo\", \"subject\": \"restaurante\" }',\n",
    "    input=\"O prato estava sem gosto e demorou muito.\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serialização de Prompts — save() e load_prompt()**\n",
    "Objeto:\n",
    "\n",
    "Qualquer PromptTemplate pode ser salvo em disco como .json ou .yaml, e recarregado depois.\n",
    "\n",
    "**Vantagens:**\n",
    "\n",
    "    Reutilização de prompts em diferentes projetos\n",
    "\n",
    "    Permite versionamento de templates\n",
    "\n",
    "    Ideal para ambientes de produção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"input\"], template=\"Conte uma piada sobre {input}\")\n",
    "prompt.save(\"prompt.yaml\")\n",
    "\n",
    "from langchain.prompts import load_prompt\n",
    "loaded_prompt = load_prompt(\"prompt.yaml\")\n",
    "print(loaded_prompt.format(input=\"galinhas\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
